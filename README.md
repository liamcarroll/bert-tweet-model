# Fine-tuning BERTweet for Sentiment Analysis

One BERT model which caught my eye when scrolling through the Huggingface website was the BERTweet model. The BERTweet model was proposed in the paper below:

[BERTweet: A pre-trained language model for English Tweets](https://www.aclweb.org/anthology/2020.emnlp-demos.2.pdf)

BERTweet is the first public large-scale pre-trained language model for English Tweets. The corpus used to pre-train BERTweet consists of 850 million English Tweets.

In the above notebook, I am going to attempt to fine-tune the BERTweet model for the purpose of sentiment analysis of Tweets.
